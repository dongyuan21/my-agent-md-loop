# Long-running Agents：Cursor 和 Anthropic 的两条路（一个堆并行，一个做记忆）

> 这篇是我看完 Cursor《Scaling long-running autonomous coding》和 Anthropic《Effective harnesses for long-running agents》后的“工程向笔记”。
>
> 先把结论放前面：
>
> - Cursor：**项目做不动？那就上人——上成百上千个 Agent。**核心问题是“怎么组织”。
> - Anthropic：**别急着加人，先让同一个 Agent 换班不失忆。**核心问题是“怎么交接”。

---

## 0. 为什么大家突然开始聊 Long-running？

短任务 Agent 现在已经挺能打了：改个 bug、写个函数、补点测试，都能交付。

但一旦你把任务升级到“项目级”：

- 从 0 搭一个完整软件
- 做一轮大迁移（框架/架构/目录结构）
- 连续几周盯一个模块做性能优化

就会立刻暴露现实问题：

1. **上下文窗口是硬上限**：对话换一次，基本等于换个工程师上班。
2. **长期目标会漂移**：做着做着就开始“顺手优化”，最后主线没了。
3. **验证经常缺席**：跑两条单测就说 OK，用户路径一走就爆。

Cursor 和 Anthropic 都没在“更大模型/更长上下文”上做文章，而是老老实实走工程路线：**组织**和**流程**。

---

## 1. Cursor：多 Agent 并行协作，先解决“怎么组织”

Cursor 的基本判断很直白：

- 单个 Agent 对“单点任务”已经够强
- 但对“项目”能力有天花板
- 想突破：**像人类团队一样并行干活**

问题当然也很人类：并行不是开线程那么简单，关键在协调。

### 1.1 两次踩坑：扁平协作看起来美，实际容易炸

Cursor 一开始想做“完全扁平”的多 Agent 协作：大家地位平等，共享一个状态文件自我协调。

#### 尝试 1：锁（lock）机制

流程大概是：

- Agent 读共享文件
- 认领任务 + 加锁
- 做完更新状态 + 释放锁

失败原因很经典（分布式系统老朋友了）：

- 有人锁太久、甚至忘了释放 → **吞吐量暴跌**
- 持锁 Agent 崩了 → **死锁**，任务永久阻塞
- 还会发生重复加锁、无锁写入 → **共享状态被写烂**

20 个 Agent 同时跑，最后有效吞吐量只剩两三个——剩下的全在排队。

#### 尝试 2：乐观并发控制（OCC）

OCC 的逻辑是：

- 读状态随便读
- 写入时检查“我上次读完到现在状态有没有变”
- 变了就写失败，重读重做

这比锁简单、也更稳。但出现了一个更“组织学”的问题：

> **群体性的风险规避**：大家都在挑安全的小任务做，核心难题没人碰。

扁平结构里没有“负责到底”的角色，项目就会一直在边角料里打转。

### 1.2 真正能跑起来的结构：Planner / Worker / Judge

Cursor 最后放弃扁平，改成三角色流水线：

- **Planner（规划者）**：像 tech lead，理解全局、持续拆任务；甚至可以派生“子规划者”并行做规划
- **Worker（工作者）**：纯执行，从任务池领一个任务就埋头做，不需要懂全局，也不跟其他 Worker 沟通
- **Judge（裁判）**：按周期检查进展、做质量评估，决定是否进入下一轮迭代

这套结构最值钱的点不是“更复杂”，而是把最容易乱的地方切开了：

- Worker 不互相协调 → 减少扯皮和重复劳动
- Planner 负责硬骨头 → 避免集体逃避
- Judge 定期纠偏 → 解决 tunnel vision（只盯局部，忘了大目标）

### 1.3 实验结果：能跑周级别任务，而且产出很猛

Cursor 做了几个实打实的实验（不是纸上谈兵）：

- **从零构建网页浏览器**：持续近一周，1000 个文件，累计写了超过 100 万行代码
- **大项目原地迁移（Solid → React）**：三周多，+266k / -193k，能过 CI 和自动化检查
- **产品模块性能优化**：Rust 重写渲染模块，速度提升 25 倍，还加了缩放/平移/弹簧过渡/运动模糊，代码直接合主干准备上线

这些例子至少说明一件事：多 Agent 并行不是“想象”，是真的能在工程上跑通。

### 1.4 Cursor 的一些“反直觉”经验

我觉得 Cursor 最有价值的是这些教训：

- **模型选择在长任务里特别关键**：有的模型更能持续专注，有的会提前“交卷”走捷径
- **不同角色适合不同模型**：比如“规划者”不一定是最强 codex
- **很多提升来自做减法**：他们试过加“集成者”来控质量/解冲突，结果制造的瓶颈比解决的问题还多
- **结构要刚刚好**：太松会冲突/重复，太紧会脆弱
- **最后还是 prompt**：系统大部分行为都归结为“你怎么写提示词”

他们也承认：这还远没到最优——比如 Planner 的唤醒机制、Agent 偶尔跑太久、需要定期重启对抗目标漂移等。

---

## 2. Anthropic（Claude Code）：先解决“换班不失忆”，让单 Agent 能跨上下文跑下去

Anthropic 的路线更像“工程管理”，核心是一个朴素问题：

> 同一个任务跨多个会话，怎么让下一轮 Agent 不用靠猜？

他们用的类比特别贴切：

- 一个团队每个工程师只能工作几十分钟，干完就换人

所以长任务干不好，不是因为大家不努力，而是没有交接制度。

### 2.1 长任务最常见的三种翻车方式

Anthropic 归纳了三种：

1. **一口气干太多**：试图一次写完整应用，结果写到一半上下文耗尽，留下半成品
2. **过早宣布胜利**：感觉“差不多能跑”就收工，功能缺一堆
3. **测试敷衍**：跑单测或 curl 一下就说 OK，端到端用户流程根本没走

共同点：Agent 不知道“全局目标长什么样”，也不知道“这一轮应该交付什么、怎么验收”。

### 2.2 双 Agent 方案：Initializer + Coding（把记忆外化到文件和 Git）

Anthropic 的解决思路很工程：

- 第一轮先把“工程骨架”和“验收标准”立起来
- 后续每轮只做一小步，做完必须可合并、可继续

他们在 Claude Agent SDK 里给出一个双 Agent 方案：

#### Initializer Agent（只在启动时出场一次）

职责：把未来能持续迭代的环境搭好。

产物包括：

- `init.sh`：启动开发服务器、跑基础验证的脚本
- `claude-progress.txt`：进度日志（交接本）
- 初始 Git 提交
- **功能清单（Feature List）**：把“用户的模糊需求”扩展成可逐条验收的功能点

最细的一刀：功能清单不用 Markdown，用 **JSON 数组**。

原因很现实：Markdown 太自由，模型很容易“顺手改结构/删条目/重写整页”。JSON 结构强约束，模型更不敢乱动。

每条功能有 steps，还有一个 `passes` 字段，默认全是 `false`。后续 Coding Agent **只允许改 passes 状态**，明确禁止删改测试描述。

#### Coding Agent（后续每轮会话）

规则就两条：

1. **一次只做一个功能点**（禁止多线程乱开）
2. **做完必须保持仓库干净**（能安全合并到主分支）

每轮流程也写得很“像上班”：

- 读 `claude-progress.txt` + `git log`：先搞清楚上轮干了啥
- 读功能清单：挑一个最高优先级且未完成的任务
- 实现 → 调试 → 测试
- 提交代码（清晰 commit message）
- 追加进度日志（下一轮接手的人一眼能懂）

这套设计的本质：**把记忆从上下文窗口里搬到仓库里**。

### 2.3 测试要像真人：浏览器自动化是补全拼图的那块

Anthropic 发现 Claude 特别爱“自信”：跑了单测/接口就觉得完成。

但很多问题只会在真实用户路径里暴露，所以他们给 Agent 配浏览器自动化工具（例如 Puppeteer MCP），要求像真实用户一样点按钮、填表单、看渲染结果。

这一步的效果是：验收从“感觉 OK”，变成“我真的走通了”。

当然也有盲区，比如浏览器原生 `alert` 这类弹窗，自动化工具可能抓不到。

---

## 3. 我怎么理解这两条路线（以及你该怎么选）

### 3.1 这不是“谁更先进”，而是“先解决哪个瓶颈”

- Cursor 解决的是：**当任务规模很大时，如何靠并行把吞吐拉上去**
- Anthropic 解决的是：**当任务跨会话时，如何保证连续性、可验证、可交接**

你可以把它理解成：

- Cursor 更像“搭一个 AI 工程团队”
- Anthropic 更像“给 AI 立工作制度”

### 3.2 如果我从 0 落地一个 Long-running Agent，我会怎么做（最小可行版）

不玩花活，先上 Anthropic 这套“外化记忆”，因为它最省、最稳、最容易复用：

1. **强约束的功能清单**：用 JSON 写 Feature List，默认全 failing
2. **每轮只做一个功能点**：做完才允许开始下一个
3. **交接物固定化**：`progress.txt` + `git log` + 可复现脚本（`init.sh`）
4. **验收从“口头”变成“可执行”**：能自动跑就自动跑，Web 就上浏览器自动化

当你发现单线程推进速度不够，再考虑 Cursor 的 Planner/Worker/Judge，把并行加进去。

### 3.3 一个很现实的结论：长跑能力靠的不是“更聪明”，而是“更可控”

长任务最怕两件事：

- 没人能说清楚“还差什么”
- 没人能证明“真的好了”

Cursor 用组织结构解决第一类问题（谁负责拆解、谁负责推进、谁负责验收）。

Anthropic 用外化状态解决第二类问题（feature list、日志、脚本、可复现测试）。

我更愿意把 Long-running Agents 理解成一句话：

> **你不是在训练一个永动机，你是在设计一个可重启、可审计、能交接的工程流程。**

---

## 4. 开放问题（也许下一波会这么演进）

两篇文章最后都留了类似的问题：

- 未来到底是“一个全能 Agent”，还是“专家团队”？
- 要不要拆出专门的测试 Agent / 质检 Agent / 清理代码 Agent？
- 这套方法能不能从 Web 开发推广到科研、金融建模等更复杂领域？

我的直觉（很不性感但可能更接近现实）：

- **先流程化，再团队化**
- 没有可验证的交付物，堆再多 Agent 都只是把混乱放大

---

### 参考

- Cursor: *Scaling long-running autonomous coding*
- Anthropic: *Effective harnesses for long-running agents*
